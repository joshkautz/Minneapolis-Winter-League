#!/usr/bin/env node

/**
 * Script to import production data into Firebase emulator
 *
 * This script imports JSON data exported by export-from-production.js
 * into running Firebase emulator instances.
 *
 * Imports:
 * - Firestore data (collections and subcollections)
 * - Authentication users (with password reset requirement)
 * - Storage files (uploaded to emulator storage bucket)
 *
 * Usage:
 * 1. Start Firebase emulators: firebase emulators:start
 * 2. Run this script: node scripts/production/import-to-emulator.js
 *
 * Options:
 * - Add --skip-auth to skip authentication import
 * - Add --skip-firestore to skip Firestore import
 * - Add --skip-storage to skip Storage import
 *
 * Note: This script can be run from any directory.
 */

import { initializeApp, cert } from 'firebase-admin/app'
import { getFirestore } from 'firebase-admin/firestore'
import { getAuth } from 'firebase-admin/auth'
import { getStorage } from 'firebase-admin/storage'
import fs from 'fs'
import path from 'path'
import { fileURLToPath } from 'url'

// Get the directory of this script
const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// Parse command line arguments
const args = process.argv.slice(2)
const skipAuth = args.includes('--skip-auth')
const skipFirestore = args.includes('--skip-firestore')
const skipStorage = args.includes('--skip-storage')

// Configure emulator hosts before initializing Firebase
process.env.FIRESTORE_EMULATOR_HOST = 'localhost:8080'
process.env.FIREBASE_AUTH_EMULATOR_HOST = 'localhost:9099'
process.env.FIREBASE_STORAGE_EMULATOR_HOST = 'localhost:9199'

// Initialize Firebase Admin SDK for emulator
const app = initializeApp({
	projectId: 'minnesota-winter-league',
	storageBucket: 'minnesota-winter-league.appspot.com',
})

// Initialize services (they will automatically connect to emulators via environment variables)
const db = getFirestore(app)
const auth = getAuth(app)
const storage = getStorage(app)

const exportDir = path.join(__dirname, 'data')

// Function to convert timestamp objects and document paths back to Firestore types
function convertFirestoreTypes(obj) {
	if (obj === null || obj === undefined) return obj

	// Handle ISO timestamp strings (exported from Firestore Timestamps)
	if (
		typeof obj === 'string' &&
		/^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}/.test(obj)
	) {
		// This looks like an ISO timestamp string, convert to Date
		return new Date(obj)
	}

	// Handle DocumentReference paths (strings like "teams/abc123" or "seasons/xyz789")
	if (typeof obj === 'string' && obj.includes('/')) {
		const pathParts = obj.split('/')
		if (pathParts.length === 2) {
			// This looks like a document path, convert to DocumentReference
			const [collectionId, documentId] = pathParts
			return db.collection(collectionId).doc(documentId)
		}
	}

	// Handle legacy Firestore Timestamp objects (if any remain)
	if (
		typeof obj === 'object' &&
		obj._seconds !== undefined &&
		obj._nanoseconds !== undefined
	) {
		// This is a Firestore Timestamp object
		return new Date(obj._seconds * 1000 + obj._nanoseconds / 1000000)
	}

	if (Array.isArray(obj)) {
		return obj.map(convertFirestoreTypes)
	}

	if (typeof obj === 'object') {
		const converted = {}
		for (const [key, value] of Object.entries(obj)) {
			converted[key] = convertFirestoreTypes(value)
		}
		return converted
	}

	return obj
}

// Function to import a collection
async function importCollection(collectionName, filePath) {
	console.log(`Importing collection: ${collectionName}`)

	try {
		const data = JSON.parse(fs.readFileSync(filePath, 'utf8'))
		const collection = db.collection(collectionName)

		let imported = 0
		let batch = db.batch()

		for (const [docId, docData] of Object.entries(data)) {
			const convertedData = convertFirestoreTypes(docData)
			const docRef = collection.doc(docId)
			batch.set(docRef, convertedData)
			imported++

			// Commit batch every 500 documents
			if (imported % 500 === 0) {
				await batch.commit()
				console.log(`  Committed ${imported} documents to ${collectionName}`)
				batch = db.batch() // Create new batch
			}
		}

		// Commit any remaining documents
		if (imported % 500 !== 0) {
			await batch.commit()
		}

		console.log(`âœ… Imported ${imported} documents to ${collectionName}`)
		return imported
	} catch (error) {
		console.error(`âŒ Error importing ${collectionName}:`, error.message)
		return 0
	}
}

// Function to import subcollections
async function importSubcollection(
	parentCollection,
	parentDocId,
	subcollectionName,
	filePath
) {
	console.log(
		`Importing subcollection: ${parentCollection}/${parentDocId}/${subcollectionName}`
	)

	try {
		const data = JSON.parse(fs.readFileSync(filePath, 'utf8'))
		const subcollection = db
			.collection(parentCollection)
			.doc(parentDocId)
			.collection(subcollectionName)

		let imported = 0
		let batch = db.batch()

		for (const [docId, docData] of Object.entries(data)) {
			const convertedData = convertFirestoreTypes(docData)
			const docRef = subcollection.doc(docId)
			batch.set(docRef, convertedData)
			imported++

			// Commit batch every 500 documents
			if (imported % 500 === 0) {
				await batch.commit()
				console.log(
					`  Committed ${imported} documents to ${parentCollection}/${parentDocId}/${subcollectionName}`
				)
				batch = db.batch() // Create new batch
			}
		}

		// Commit any remaining documents
		if (imported % 500 !== 0) {
			await batch.commit()
		}

		console.log(
			`âœ… Imported ${imported} documents to ${parentCollection}/${parentDocId}/${subcollectionName}`
		)
		return imported
	} catch (error) {
		console.error(
			`âŒ Error importing ${parentCollection}/${parentDocId}/${subcollectionName}:`,
			error.message
		)
		return 0
	}
}

// Function to clear all collections
async function clearAllCollections() {
	console.log('Clearing existing collections...\n')

	try {
		// Get all collections
		const collections = await db.listCollections()

		for (const collection of collections) {
			console.log(`Clearing collection: ${collection.id}`)

			// Get all documents in batches
			let batch = db.batch()
			let batchCount = 0

			const snapshot = await collection.get()
			for (const doc of snapshot.docs) {
				batch.delete(doc.ref)
				batchCount++

				// Commit batch every 500 deletions
				if (batchCount >= 500) {
					await batch.commit()
					batch = db.batch()
					batchCount = 0
				}
			}

			// Commit any remaining deletions
			if (batchCount > 0) {
				await batch.commit()
			}

			console.log(
				`âœ… Cleared ${snapshot.docs.length} documents from ${collection.id}`
			)
		}

		console.log('âœ… All collections cleared\n')
	} catch (error) {
		console.error('âŒ Error clearing collections:', error.message)
		throw error
	}
}

/**
 * Clear all authentication users
 */
async function clearAllUsers() {
	console.log('ğŸ” Clearing existing authentication users...\n')

	try {
		let usersCleared = 0
		let nextPageToken

		do {
			// List users in batches
			const listUsersResult = await auth.listUsers(1000, nextPageToken)

			if (listUsersResult.users.length > 0) {
				// Delete users in batch
				const uids = listUsersResult.users.map((user) => user.uid)
				await auth.deleteUsers(uids)
				usersCleared += uids.length

				console.log(
					`   ğŸ—‘ï¸  Deleted ${uids.length} users (total: ${usersCleared})`
				)
			}

			nextPageToken = listUsersResult.pageToken
		} while (nextPageToken)

		console.log(`âœ… Cleared ${usersCleared} authentication users\n`)
		return usersCleared
	} catch (error) {
		console.error('âŒ Error clearing authentication users:', error.message)
		throw error
	}
}

/**
 * Clear all storage files
 */
async function clearAllStorage() {
	console.log('ğŸ“¦ Clearing existing storage files...\n')

	try {
		const bucket = storage.bucket()
		let filesCleared = 0

		// Get all files in the bucket
		const [files] = await bucket.getFiles()

		if (files.length === 0) {
			console.log('âœ… No storage files to clear\n')
			return 0
		}

		console.log(`   ğŸ“ Found ${files.length} files to delete`)

		// Delete files in batches
		const batchSize = 100
		for (let i = 0; i < files.length; i += batchSize) {
			const batch = files.slice(i, i + batchSize)

			// Delete files in parallel within each batch
			await Promise.all(
				batch.map(async (file) => {
					try {
						await file.delete()
						filesCleared++
					} catch (error) {
						console.log(
							`   âš ï¸  Failed to delete ${file.name}: ${error.message}`
						)
					}
				})
			)

			console.log(
				`   ğŸ—‘ï¸  Deleted ${Math.min(i + batchSize, files.length)}/${files.length} files`
			)
		}

		console.log(`âœ… Cleared ${filesCleared} storage files\n`)
		return filesCleared
	} catch (error) {
		console.error('âŒ Error clearing storage files:', error.message)
		throw error
	}
}

async function importAuthentication() {
	if (skipAuth) {
		console.log('ğŸ” Skipping authentication import (--skip-auth flag)')
		return 0
	}

	const authDir = path.join(exportDir, 'auth_export')
	const accountsFile = path.join(authDir, 'accounts.json')

	if (!fs.existsSync(accountsFile)) {
		console.log('ğŸ” No authentication data found to import')
		return 0
	}

	console.log('ğŸ” Importing authentication users...')

	try {
		// Clear existing users first
		await clearAllUsers()

		const authData = JSON.parse(fs.readFileSync(accountsFile, 'utf8'))
		let importedUsers = 0

		for (const userData of authData.users) {
			try {
				// Create user in Auth emulator
				const userRecord = await auth.createUser({
					uid: userData.uid,
					email: userData.email,
					emailVerified: userData.emailVerified,
					displayName: userData.displayName,
					photoURL: userData.photoURL,
					phoneNumber: userData.phoneNumber,
					disabled: userData.disabled,
					// Note: Password cannot be imported for security reasons
					// Users will need to reset their passwords
				})

				// Set custom claims if they exist
				if (
					userData.customClaims &&
					Object.keys(userData.customClaims).length > 0
				) {
					await auth.setCustomUserClaims(userRecord.uid, userData.customClaims)
				}

				importedUsers++

				if (importedUsers % 50 === 0) {
					console.log(`   ğŸ‘¤ Imported ${importedUsers} users...`)
				}
			} catch (userError) {
				if (userError.code === 'auth/uid-already-exists') {
					console.log(`   âš ï¸  User ${userData.uid} already exists, skipping...`)
				} else {
					console.error(
						`   âŒ Error importing user ${userData.uid}:`,
						userError.message
					)
				}
			}
		}

		console.log(`   âœ… Successfully imported ${importedUsers} users`)
		console.log(
			`   âš ï¸  NOTE: Users will need to reset passwords (cannot import password hashes)`
		)

		return importedUsers
	} catch (error) {
		console.error('âŒ Error importing authentication data:', error)
		return 0
	}
}

/**
 * Import storage files to emulator
 */
async function importStorage() {
	console.log('ğŸ“¦ Importing Storage files...')

	const storageExportDir = path.join(exportDir, 'storage_export')
	const metadataFile = path.join(storageExportDir, 'metadata.json')

	try {
		// Clear existing storage files first
		await clearAllStorage()

		// Check if storage export exists
		if (!fs.existsSync(storageExportDir)) {
			console.log('   âš ï¸  No storage export found, skipping...')
			return 0
		}

		if (!fs.existsSync(metadataFile)) {
			console.log('   âš ï¸  No storage metadata found, skipping...')
			return 0
		}

		const metadata = JSON.parse(fs.readFileSync(metadataFile, 'utf8'))
		const bucket = storage.bucket()
		let uploadedFiles = 0

		console.log(`   ğŸ“ Found ${metadata.files?.length || 0} files to import`)

		if (!metadata.files || metadata.files.length === 0) {
			console.log('   âœ… No files to import')
			return 0
		}

		// Upload each file
		for (const fileInfo of metadata.files) {
			try {
				// Convert storage path to filesystem path (replace / with _)
				const filesystemName = fileInfo.name.replace(/\//g, '_')
				const localFilePath = path.join(storageExportDir, filesystemName)

				if (!fs.existsSync(localFilePath)) {
					console.log(
						`   âš ï¸  File not found: ${fileInfo.name} (looking for: ${filesystemName})`
					)
					continue
				}

				// Upload file to emulator storage with original name
				const file = bucket.file(fileInfo.name)
				await file.save(fs.readFileSync(localFilePath), {
					metadata: {
						contentType: fileInfo.contentType,
						metadata: fileInfo.customMetadata,
					},
				})

				uploadedFiles++
				if (uploadedFiles % 10 === 0) {
					console.log(
						`   ğŸ“¤ Uploaded ${uploadedFiles}/${metadata.files.length} files...`
					)
				}
			} catch (fileError) {
				console.log(
					`   âš ï¸  Failed to upload ${fileInfo.name}: ${fileError.message}`
				)
			}
		}

		console.log(`   âœ… Successfully imported ${uploadedFiles} storage files`)
		return uploadedFiles
	} catch (error) {
		console.error('âŒ Error importing storage data:', error)
		return 0
	}
}

async function importAllData() {
	console.log('ğŸš€ Starting comprehensive import to Firebase emulators...\n')
	console.log(`ğŸ“‚ Import directory: ${exportDir}\n`)

	const importStats = {
		firestore: { collections: 0, documents: 0 },
		auth: { users: 0 },
		storage: { files: 0 },
	}

	try {
		// Check if the export directory exists
		if (!fs.existsSync(exportDir)) {
			console.error(`âŒ Export directory not found: ${exportDir}`)
			console.error(
				'Please run the export script first: node scripts/production/export-from-production.js'
			)
			process.exit(1)
		}

		// Import Authentication Data
		if (!skipAuth) {
			importStats.auth.users = await importAuthentication()
		} else {
			console.log('ğŸ” Skipping Authentication import (--skip-auth flag)')
		}

		// Import Firestore Data
		if (!skipFirestore) {
			console.log('\nğŸ”¥ Importing Firestore data...')

			const firestoreDir = path.join(exportDir, 'firestore_export')

			if (!fs.existsSync(firestoreDir)) {
				console.log(
					'âš ï¸  No Firestore export directory found, skipping Firestore import'
				)
			} else {
				// Clear existing Firestore data first
				await clearAllCollections()

				// Read all files in the export directory
				const files = fs.readdirSync(firestoreDir)

				// Separate main collections from subcollections
				const mainCollections = []
				const subcollections = []

				for (const file of files) {
					if (file.endsWith('.json')) {
						const fileName = file.replace('.json', '')

						if (fileName.includes('__')) {
							// This is a subcollection file
							subcollections.push(file)
						} else if (!fileName.includes('metadata')) {
							// This is a main collection file (exclude metadata files)
							mainCollections.push(file)
						}
					}
				}

				console.log(
					`   ğŸ“‹ Found ${mainCollections.length} main collections and ${subcollections.length} subcollection files\n`
				)

				let totalImported = 0

				// Import main collections first
				for (const file of mainCollections) {
					const collectionName = file.replace('.json', '')
					const filePath = path.join(firestoreDir, file)
					const imported = await importCollection(collectionName, filePath)
					totalImported += imported
					importStats.firestore.documents += imported
				}

				console.log('   ğŸ“‚ Importing subcollections...\n')

				// Import subcollections
				for (const file of subcollections) {
					const fileName = file.replace('.json', '')
					const parts = fileName.split('__')

					if (parts.length === 3) {
						const [parentCollection, parentDocId, subcollectionName] = parts
						const filePath = path.join(firestoreDir, file)
						const imported = await importSubcollection(
							parentCollection,
							parentDocId,
							subcollectionName,
							filePath
						)
						totalImported += imported
						importStats.firestore.documents += imported
					}
				}

				importStats.firestore.collections = mainCollections.length
				console.log(
					`   âœ… Firestore import completed: ${totalImported} documents`
				)
			}
		} else {
			console.log('ğŸ”¥ Skipping Firestore import (--skip-firestore flag)')
		}

		// Import Storage Data
		if (!args.includes('--skip-storage')) {
			console.log('\nï¿½ Importing Storage data...')
			importStats.storage.files = await importStorage()
		} else {
			console.log('\nï¿½ Skipping Storage import (--skip-storage flag)')
		}

		console.log('\nğŸ‰ Import completed successfully!')
		console.log('\nğŸ“Š Import Summary:')
		console.log(
			`   ğŸ”¥ Firestore: ${importStats.firestore.collections} collections, ${importStats.firestore.documents} documents`
		)
		console.log(`   ğŸ” Authentication: ${importStats.auth.users} users`)
		console.log(`   ğŸ“¦ Storage: ${importStats.storage.files} files`)

		if (!skipAuth && importStats.auth.users > 0) {
			console.log('\nâš ï¸  IMPORTANT: Users will need to reset their passwords')
			console.log('   Password hashes cannot be imported for security reasons')
		}

		console.log('\nğŸŒ Emulator URLs:')
		console.log('   Firestore: http://127.0.0.1:4000/firestore')
		console.log('   Authentication: http://127.0.0.1:4000/auth')
	} catch (error) {
		console.error('âŒ Import failed:', error)
		process.exit(1)
	}
}

// Run the import
importAllData()
	.then(() => {
		console.log('\nâœ… Import script completed successfully')
		process.exit(0)
	})
	.catch((error) => {
		console.error('âŒ Import script failed:', error)
		process.exit(1)
	})
